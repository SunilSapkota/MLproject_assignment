{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv\")\n",
    "data=pd.DataFrame(pd.read_csv(\"/kaggle/input/bank-customer-churn-modeling/Churn_Modelling.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['RowNumber', 'CustomerId','Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 * len(data[data['tenure'].isna()]) / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['tenure'].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tenure'] = data['tenure'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проведем кодирование с помощью OHE\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "#Стандартизируем признаки с помощью StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric = ['creditscore', 'age', 'balance', 'estimatedsalary']\n",
    "scaler.fit(data[numeric])\n",
    "data[numeric] = scaler.transform(data[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#С помощью train_test_split Разделим наш датасет на следующие выборки \n",
    "features = data.drop(['exited'], axis=1)\n",
    "target = data['exited']\n",
    "\n",
    "features_train, features_x, target_train, target_x = train_test_split(features, target, train_size=0.6, test_size=0.4, random_state=12345)\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(features_x, target_x, test_size=0.5, random_state=12345)\n",
    "\n",
    "print('Training set size:', features_train.shape[0])\n",
    "print('Validating set size:', features_valid.shape[0])\n",
    "print('Test set size:',features_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_roc = 0\n",
    "best_depth = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in range(1,13):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    \n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    predictions_model = model.predict(features_valid)\n",
    "    \n",
    "    f1_model = f1_score(target_valid, predictions_model)\n",
    "    \n",
    "    if f1_model > best_f1:\n",
    "        best_model = model\n",
    "        best_f1 = f1_model\n",
    "        best_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:,1])\n",
    "        best_depth = depth\n",
    "\n",
    "print('F1 Decision Tree:', best_f1)\n",
    "print('ROC Best result:', best_roc)\n",
    "print('Depth Tree:', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_roc = 0\n",
    "best_depth = 0\n",
    "best_est = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for est in range(1,61):\n",
    "    for depth in range(1,31):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=est)\n",
    "        model.fit(features_train, target_train)\n",
    "        predictions_model = model.predict(features_valid)\n",
    "        f1_model = f1_score(target_valid, predictions_model)\n",
    "        \n",
    "        if f1_model > best_f1:\n",
    "            best_model = model\n",
    "            best_f1 = f1_model\n",
    "            best_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:,1])\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "  \n",
    "print('F1 Random Forest:', best_f1)\n",
    "print('ROC Best result:', best_roc)\n",
    "print('Forest depth:', best_depth)\n",
    "print('Amount of estimators:', best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predictions_model = model.predict(features_valid)\n",
    "f1_model = f1_score(target_valid, predictions_model)\n",
    "roc_model = roc_auc_score(target_valid, model.predict_proba(features_valid)[:,1])\n",
    "\n",
    "print('F1 Model:',f1_model)\n",
    "print('ROC Model:', roc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_valid.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test.value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_roc = 0\n",
    "best_depth=0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1, 26):\n",
    "    for depth in range (1, 26):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced')\n",
    "        \n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        predictions_model = model.predict(features_valid) \n",
    "        \n",
    "        f1_model = f1_score(target_valid, predictions_model)\n",
    "\n",
    "        if f1_model > best_f1:\n",
    "            best_model = model\n",
    "            best_f1 = f1_model\n",
    "            best_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:,1])\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print(\"F1 Best Model:\", f1_model) \n",
    "print(\"ROC Best Model:\", best_roc)\n",
    "print(\"Depth Tree:\", best_depth) \n",
    "print(\"Amount of etimators:\", best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target==0]\n",
    "    features_ones = features[target==1]\n",
    "    target_zeros=target[target==0]\n",
    "    target_ones=target[target==1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros]+[features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros]+[target_ones]*repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
